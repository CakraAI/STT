# This is a Dockerfile useful for training models with Coqui STT.
# You can train "acoustic models" with audio + Tensorflow, and
# you can create "scorers" with text + KenLM.

FROM ghcr.io/reuben/manylinux_2_24:2022-03-31-361e6b6 as py38-venv
ENV DEBIAN_FRONTEND=noninteractive

ENV VIRTUAL_ENV=/venv
ENV PATH="$VIRTUAL_ENV/bin:$PATH"
RUN /opt/python/cp38*/bin/python -m venv /venv && \
    pip install --upgrade pip wheel setuptools

FROM py38-venv AS gen-scorer-package-build

COPY native_client /code/native_client
COPY tensorflow /code/tensorflow
COPY ci_scripts /code/ci_scripts
WORKDIR /code
RUN ./ci_scripts/tf-setup.sh && \
    ./ci_scripts/gen-scorer-package-build.sh && \
    cp tensorflow/bazel-bin/native_client/generate_scorer_package . && \
    cd tensorflow && /code/bin/bazel clean && rm -rf /code/bin /code/dls

FROM ghcr.io/reuben/manylinux_2_24:2022-03-31-361e6b6 AS kenlm-build
ENV DEBIAN_FRONTEND=noninteractive

RUN apt-get update && \
    apt-get install -y --no-install-recommends \
    build-essential cmake libboost-system-dev \
    libboost-thread-dev libboost-program-options-dev \
    libboost-test-dev libeigen3-dev zlib1g-dev \
    libbz2-dev liblzma-dev && \
    rm -rf /var/lib/apt/lists/*

# Build KenLM to generate new scorers
COPY kenlm /code/kenlm
RUN mkdir -p /code/kenlm/build && \
    cd /code/kenlm/build && \
    cmake .. && \
    ( make -j $(nproc) || \
    ( echo "ERROR: Failed to build KenLM."; \
    echo "ERROR: Make sure you update the kenlm submodule on host before building this Dockerfile."; \
    echo "ERROR: $ cd STT; git submodule update --init kenlm"; \
    exit 1; ) ) && \
    cd /code && \
    cp -R /code/kenlm/build/bin /code/kenlm-bin && \
    rm -rf /code/kenlm/build

FROM py38-venv as decoder-build

COPY native_client /code/native_client
COPY training/coqui_stt_training/VERSION /code/training/coqui_stt_training/VERSION
COPY VERSION /code/VERSION
COPY training/coqui_stt_training/GRAPH_VERSION /code/training/coqui_stt_training/GRAPH_VERSION
COPY GRAPH_VERSION /code/GRAPH_VERSION
COPY native_client/ctcdecode/workspace_status.cc /code/native_client/ctcdecode/workspace_status.cc

# Build CTC decoder first, to avoid clashes on incompatible versions upgrades
WORKDIR /code
RUN make -C native_client/ctcdecode bindings NUM_PROCESSES=$(nproc) && \
    cp native_client/ctcdecode/dist/*.whl . && \
    make -C native_client/ctcdecode clean

FROM nvcr.io/nvidia/tensorflow:22.02-tf1-py3
ENV DEBIAN_FRONTEND=noninteractive

COPY . /code
COPY --from=decoder-build /code/*.whl /code
COPY --from=kenlm-build /code/kenlm-bin /code/kenlm/build/bin
COPY --from=gen-scorer-package-build /code/generate_scorer_package /code

# Install STT
# Use decoder wheel from previous stage
# TensorFlow GPU should already be installed on the base image,
# and we don't want to break that
WORKDIR /code
RUN pip install --upgrade coqui_stt_ctcdecoder-*.whl && \
    DS_NODECODER=y DS_NOTENSORFLOW=y pip install --upgrade -e . && \
    ./bin/run-ldc93s1.sh && rm -rf ~/.local/share/stt
